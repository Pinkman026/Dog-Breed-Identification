{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务介绍\n",
    "\n",
    "在这次练习中，我们需要实战Kaggle在两年前的一个比赛，狗的品种识别。链接在 https://www.kaggle.com/c/dog-breed-identification 。\n",
    "\n",
    "在这个比赛中，我们需要使用训练数据，利用深度学习的方法，对测试集图像中的狗进行识别，比赛中狗的种类一共有120种。这个比赛的数据集实际上是著名的ImageNet的子集数据集。ImageNet 是一个计算机视觉系统识别的任务， 是目前世界上图像识别最大的数据库，总共有1000个类别。\n",
    "\n",
    "下图展示了数据集中一些狗的示例。\n",
    "\n",
    "![img](imgs/example.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始之前\n",
    "\n",
    "开始之前有以下的准备工作需要做：\n",
    "\n",
    "1. 需要先在Kaggle上注册账号，然后点击 Late submission，表明同意比赛的规则，这时就可以下载数据集了。\n",
    "2. 需要安装好Pytorch，Pytorch及GPU相关驱动的安装可以参考这个链接：https://blog.csdn.net/Barry_J/article/details/81079218 ；最好能在支持的GPU上面运行程序，可以节省很多的时间，如果没有GPU，直接用CPU跑当然也是可行的，这次任务需要的资源并不多。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据相关操作\n",
    "\n",
    "下载好的数据包含两个文件夹和一个文件，`test`, `train`和`labels.csv`，其中`train`里包含我们训练模型需要用到的数据，`test`中包含最后需要提交上去测试结果的图片，`labels.csv`中包含训练数据对应的标签，他们是通过文件名来对应的。\n",
    "\n",
    "先导入一些之后会用到的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pillow in c:\\users\\p51\\anaconda3\\lib\\site-packages (5.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.2, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: tqdm in c:\\users\\p51\\anaconda3\\lib\\site-packages (4.30.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.2, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pandas in c:\\users\\p51\\anaconda3\\lib\\site-packages (0.25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\p51\\anaconda3\\lib\\site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\p51\\anaconda3\\lib\\site-packages (from pandas) (1.17.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\p51\\anaconda3\\lib\\site-packages (from pandas) (2019.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\p51\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.2, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: scipy in c:\\users\\p51\\anaconda3\\lib\\site-packages (1.3.1)\n",
      "Requirement already satisfied: sklearn in c:\\users\\p51\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\p51\\anaconda3\\lib\\site-packages (from scipy) (1.17.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\p51\\anaconda3\\lib\\site-packages (from sklearn) (0.19.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.2, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# 如果除了pytorch提示有库不存在，可以运行以下的命令\n",
    "!pip install pillow\n",
    "!pip install tqdm\n",
    "!pip install pandas\n",
    "!pip install scipy sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为给定的标签是csv格式的，我们首先得通过 `pandas` 来读出训练集中所有图像的类别，以及所有的文件名。\n",
    "\n",
    "**这里需要将`data_dir`修改为存储数据的路径。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"E:/data/dog-breed-identification/\"\n",
    "csv_path = os.path.join(data_dir, 'labels.csv')\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "assert os.path.exists(csv_path)\n",
    "# 如果 assert 报错，检查一下数据的路径！\n",
    "\n",
    "train_csv = pd.read_csv(csv_path)\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，id是图像的名字，breed是这个图像对应狗的品种。接下来我们需要将品种映射到一个类别的标签（数字），通过 sklearn 中的标签编码来实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "映射后的标签 [19 37 85 ...  3 75 28]\n",
      "训练集的大小 (10222,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing.label import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(train_csv.breed)\n",
    "print(\"映射后的标签\", labels)\n",
    "print(\"训练集的大小\", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了验证我们模型的表现效果，我们需要从训练数据中随机划分个验证集出来，通过`sklearn.model_selection.train_test_split`可以很方便的做到这一点，参数中的`test_size`控制了选择多少比例的数据作为验证集，这里取了0.1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据数 9199\n",
      "验证数据数 1023\n"
     ]
    }
   ],
   "source": [
    "filenames = train_csv.id.values\n",
    "filenames_train, filenames_val, labels_train, labels_val = \\\n",
    "    train_test_split(filenames, labels, test_size=0.1, stratify=labels)\n",
    "print(\"训练数据数\", len(filenames_train))\n",
    "print(\"验证数据数\", len(filenames_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后定义一下数据集DataSet类，通过这个 DataSet 以及之后的 DataLoader 可以很方便的利用到 Pytorch 的特性，来并行化的读取数据，最简单的DataSet类的实现，需要实现以下几个成员函数：`__init__`来进行这个数据集的初始化，定义一些与数据集相关的参数；`__len__`通过这个函数返回数据集的大小；`__getitem__`是最重要的一个函数，需要通过这个函数利用数据索引来得到所对应的数据。\n",
    "\n",
    "以下是DataSet需要实现的代码框架\n",
    "\n",
    "```python\n",
    "class CustomDataset(data.Dataset):#继承自 data.Dataset\n",
    "    def __init__(self):\n",
    "        # TODO\n",
    "        # 1. Initialize file path or list of file names.\n",
    "        pass\n",
    "    def __getitem__(self, index):\n",
    "        # TODO\n",
    "        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
    "        # 2. Preprocess the data (e.g. torchvision.Transform).\n",
    "        # 3. Return a data pair (e.g. image and label).\n",
    "        #\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        # You should change 0 to the total size of your dataset.\n",
    "        return 0\n",
    "\n",
    "```\n",
    "\n",
    "Dataset类是读入数据集数据并且对读入的数据进行了索引。但是光有这个功能是不够的，由于现在我们处理的数据量一般都很大，还需要以下的几个功能\n",
    "\n",
    "- 得到批量的数据，一批一批送到网络\n",
    "- 由于读取数据是一个很耗费CPU的过程，而且现在CPU基本都是多核的，需要有效利用起来，所以需要有并行读取数据的功能\n",
    "- 需要能够将数据随机重组，由于训练集可能有人为收集数据时留下的顺序信息，这个信息会影响到模型有效学习特征，需要将训练数据随机读取，这个如果自己每次都要实现会很麻烦。测试集一般不需要随机操作。\n",
    "\n",
    "\n",
    "\n",
    "这时候就需要Dataloader类了，它为我们提供的常用操作有：batch_size(每个batch的大小), shuffle(是否进行shuffle操作), num_workers(加载数据的时候使用几个子进程)。Dataloader这个类并不需要我们自己设计代码，我们只需要利用DataLoader类读取我们设计好的Dataset子类即可：\n",
    "\n",
    "```python\n",
    "    # 利用dataloader读取我们的数据对象，并设定batch-size和工作进程\n",
    "    loader = DataLoader(train_dataset, batch_size=16, num_workers=4, shuffle=True)\n",
    "```\n",
    "\n",
    "\n",
    "在接下来的代码中，我们来定义狗的品种这个数据集，它需要初始化的是`filenames`, `labels`, `root_dir`和`transform`，其中`filenames`是一个python的list，里面存放数据集中的图片名，`labels`是这些图片对应的标签，`root_dir`是这些数据存放的路径，train的数据存放在`train`文件夹下，test的数据存放在`test`文件夹下，`transform`会在后续进行说明。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogDataset(Dataset):\n",
    "    \"\"\"Dog Breed Dataset\"\"\"\n",
    "\n",
    "    def __init__(self, filenames, labels, root_dir, transform=None):\n",
    "        assert len(filenames) == len(labels)\n",
    "        self.filenames = filenames\n",
    "        self.labels = labels\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        label = self.labels[item]\n",
    "        img_name = os.path.join(self.root_dir, self.filenames[item] + '.jpg')\n",
    "\n",
    "        with Image.open(img_name) as f:\n",
    "            img = f.convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.labels is None:\n",
    "            return img, self.filenames[item]\n",
    "        else:\n",
    "            return img, self.labels[item]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在的神经网络都设计的越来越深，有很强的拟合能力，一般来说，为了避免我们的神经网络对训练数据过拟合，即单纯是把所有的训练数据都记住，然后给出一个结果，我们可以在训练的时候对数据做很多随机的操作，来避免这种现象。常见的随机操作有：\n",
    "\n",
    "- 随机裁剪，先将图像放大一点，然后在随机的一个位置裁剪出来指定大小的图像\n",
    "- 随机旋转和翻转图像，因为一个狗的照片镜像或者旋转一下还是一个狗，所以可以通过随机翻转的方法来避免过拟合\n",
    "- 图像标准化，在计算机中存储图像一般是8位无符号数，直接在图像上进行学习比较困难，需要将其归一化到(0,1)范围内，这样可以加快网络的收敛速度\n",
    "\n",
    "\n",
    "可以把`transform`当作一个“函数”，它的输入可以是一个图像数据，输出可以是我们提前设计的处理后的Tensor。\n",
    "\n",
    "Pytorch 中关于`transform`的更多介绍可以参考：https://blog.csdn.net/u011995719/article/details/85107009\n",
    "\n",
    "接下来的代码中，我们分别定义训练集和验证集对应的 `transform`。其中训练集用到了以下的`transform`：\n",
    "\n",
    "1. `RandomResizedCrop`：随机将图像放大然后进行裁剪\n",
    "2. `RandomHorizontalFlip`：随机将图像镜像翻转\n",
    "3. `ToTensor`：将图像转化为pytorch的tensor\n",
    "4. `Normalize`：将图像归一化到给定的均值和标准差下\n",
    "\n",
    "验证集用到了以下的`transform`：\n",
    "\n",
    "1. `Resize`：由于网络输入是给定的，通过这一步确保输入图像的大小与网络输入匹配\n",
    "2. `ToTenser`：将图像转化为pytorch的tensor\n",
    "3. `Normalize`：将图像归一化到给定的均值和标准差下\n",
    "\n",
    "确定好了要进行的操作以后，通过`torchvision.transform`来将这几种操作合起来，得到一个完整的操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.RandomResizedCrop(224, scale=(0.75, 1)),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                     std=[0.229, 0.224, 0.225])\n",
    "                                ])\n",
    "val_transform = transforms.Compose([transforms.Resize([224, 224]),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                    std=[0.229, 0.224, 0.225])\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义好 `transform` 以后，我们就可以实例化我们的 `dataset`，然后通过 `torch.utils.data.DataLoader` 得到一个可以迭代的对象来批量并行读取我们的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9199\n",
      "1023\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = DogDataset(filenames_train, labels_train, train_dir, transform=train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataset = DogDataset(filenames_val, labels_val, train_dir, transform=val_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型相关操作\n",
    "\n",
    "将数据都准备好以后，需要准备我们的模型。\n",
    "\n",
    "在本次任务中，我们将采用迁移学习中的模型迁移，迁移学习是通过从已学习的相关任务中转移知识来改善新任务的学习。在很多时候我们由于数据量或者计算资源的限制，从头开始训练一个网络是不现实的，比如这次任务中用到的网络。这时，使用迁移学习是一个很不错的选择。\n",
    "\n",
    "迁移学习是通过将别人提前训练好的模型迁移到我们任务上来提升我们模型的性能。这个提前训练好的模型叫做预训练模型，Pytorch提供了很多预训练模型，这里我们使用在 ImageNet 上的预训练模型`resnet50`，它的网络结构如下图所示。\n",
    "\n",
    "![img](imgs/resnet.png)\n",
    "\n",
    "关于深度残差网络的详细信息，可以参考它的论文 https://arxiv.org/abs/1512.03385\n",
    "\n",
    "通过以下的方式在 Pytorch 得到预训练的模型。这边我们把前面所有层的权重都固定，然后把最后的一层全连接层改成这里狗的品种数，只学习最后一层全连接层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = 120 # 总共有120种的狗\n",
    "net = torchvision.models.resnet50(pretrained=True) # 得到预训练模型\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = False # 固定住所有的权重\n",
    "net.fc = torch.nn.Linear(2048, n_class) # 将最后的全连接层改掉"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样就定义好了我们的网络，接下来可以进行对这个网络进行训练了，训练神经网络有以下两个要素：\n",
    "\n",
    "1. 损失函数：网络需要优化的目标，我们的目的就是通过网络的学习尽可能让损失函数更小。这边使用多分类中很常用到的交叉熵损失。交叉熵刻画的是两个概率分布之间的距离，越小说明网络的输出与真实的结果越接近。损失函数在 torch.nn 下定义了很多常见的损失函数。\n",
    "2. 优化器：为了优化我们的神经网络，加快训练的速度，需要使用一些优化的策略。在pytorch中提供了torch.optim方法优化我们的神经网络，torch.optim是实现各种优化算法的包。一般来说直接使用这些优化器就可以了，没有必要定义自己的优化器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss() # 交叉熵损失函数\n",
    "optimizer = torch.optim.Adam(net.fc.parameters(), lr=0.0001)  # 学习率为0.0001的Adam优化器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义好了优化器和损失函数以后，我们就可以进行网络的学习了，接下来定义一个通用的学习函数，通过这个函数可以进行一轮网络的学习，它有以下几个参数：\n",
    "\n",
    "- `net`：我们需要学习的网络\n",
    "- `data_iter`：可以迭代的 DataLoader\n",
    "- `criterion`：loss函数\n",
    "- `use_cuda`：是否使用 GPU 加速训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(net, data_iter, criterion, optimizer, use_cuda, print_every=50):\n",
    "    net.train()\n",
    "    correct = 0\n",
    "    for batch_idx, (x, y) in tqdm(enumerate(data_iter)):\n",
    "        if use_cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "        x = Variable(x)\n",
    "        y = Variable(y)\n",
    "        optimizer.zero_grad()\n",
    "        logits = net(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        prediction = torch.argmax(logits, 1)\n",
    "        cur_correct = (prediction == y).sum().float()\n",
    "        cur_accuracy = cur_correct / x.shape[0]\n",
    "        correct += cur_correct\n",
    "\n",
    "        if batch_idx % print_every == 0:\n",
    "            print('current batch: {}/{} ({:.0f}%)\\tLoss: {:.6f}\\tAcc: {:.6f}'.format(\n",
    "                batch_idx, len(data_iter),\n",
    "                100. * batch_idx / len(data_iter), loss.data.item(), cur_accuracy))\n",
    "\n",
    "    accuracy = correct / len(data_iter.dataset)\n",
    "    print('Train epoch Acc: {:.6f}'.format(accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "类似地，我们可以定义验证的过程，在每次训练完一轮网络后验证我们模型的效果，这样可以提前将网络训练过程停止，防止在训练集上发生过拟合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_epoch(net, data_iter, criterion, use_cuda):\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    net.eval() # 将网络设置为验证的模式，不会改变参数\n",
    "    for batch_idx, (x, y) in tqdm(enumerate(data_iter)):\n",
    "        if use_cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "        x = Variable(x)\n",
    "        y = Variable(y)\n",
    "        logits = net(x)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        test_loss += loss.data.item()\n",
    "        prediction = torch.argmax(logits, 1)\n",
    "        cur_correct = (prediction == y).sum().float()\n",
    "        correct += cur_correct\n",
    "\n",
    "    test_loss /= len(data_iter.dataset)\n",
    "    accuracy = correct / len(data_iter.dataset)\n",
    "\n",
    "    print('\\nVal set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "          .format(test_loss, correct, len(data_iter.dataset), 100. * accuracy))\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义好训练过程和验证过程以后，我们可以设置一些训练时的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10 # 设置网络迭代最多10次\n",
    "use_cuda = torch.cuda.is_available() # 查看是否有 GPU 可用\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 0/288 (0%)\tLoss: 4.824439\tAcc: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:15,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 50/288 (17%)\tLoss: 4.486506\tAcc: 0.062500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:30,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 100/288 (35%)\tLoss: 4.073093\tAcc: 0.281250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:45,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 150/288 (52%)\tLoss: 3.848574\tAcc: 0.312500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [01:00,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 200/288 (69%)\tLoss: 3.598921\tAcc: 0.406250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:16,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 250/288 (87%)\tLoss: 3.164575\tAcc: 0.562500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "288it [01:27,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch Acc: 0.336341\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:14,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 0.0906, Accuracy: 656.0/1023 (64%)\n",
      "\n",
      "Epoch:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 0/288 (0%)\tLoss: 2.870648\tAcc: 0.718750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:14,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 50/288 (17%)\tLoss: 2.784112\tAcc: 0.562500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:29,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 100/288 (35%)\tLoss: 2.447611\tAcc: 0.750000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:44,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 150/288 (52%)\tLoss: 2.257046\tAcc: 0.781250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:59,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 200/288 (69%)\tLoss: 2.530027\tAcc: 0.468750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:14,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 250/288 (87%)\tLoss: 1.859881\tAcc: 0.781250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "288it [01:25,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch Acc: 0.696706\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:15,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 0.0575, Accuracy: 792.0/1023 (77%)\n",
      "\n",
      "Epoch:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 0/288 (0%)\tLoss: 1.826648\tAcc: 0.781250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:15,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 50/288 (17%)\tLoss: 1.990918\tAcc: 0.656250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:31,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 100/288 (35%)\tLoss: 1.610246\tAcc: 0.812500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:46,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 150/288 (52%)\tLoss: 1.297879\tAcc: 0.875000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [01:01,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 200/288 (69%)\tLoss: 1.527655\tAcc: 0.687500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:17,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 250/288 (87%)\tLoss: 1.392835\tAcc: 0.906250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "288it [01:28,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch Acc: 0.781389\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:15,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 0.0418, Accuracy: 822.0/1023 (80%)\n",
      "\n",
      "Epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 0/288 (0%)\tLoss: 1.300671\tAcc: 0.937500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:14,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 50/288 (17%)\tLoss: 1.494518\tAcc: 0.750000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:29,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 100/288 (35%)\tLoss: 1.189296\tAcc: 0.750000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:44,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 150/288 (52%)\tLoss: 1.299743\tAcc: 0.781250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [01:02,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 200/288 (69%)\tLoss: 1.057744\tAcc: 0.875000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:23,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 250/288 (87%)\tLoss: 1.294360\tAcc: 0.875000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "288it [01:56,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch Acc: 0.819437\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:20,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 0.0338, Accuracy: 842.0/1023 (82%)\n",
      "\n",
      "Epoch:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 0/288 (0%)\tLoss: 1.141766\tAcc: 0.781250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:14,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 50/288 (17%)\tLoss: 1.076124\tAcc: 0.812500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:29,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 100/288 (35%)\tLoss: 0.993151\tAcc: 0.781250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:44,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 150/288 (52%)\tLoss: 0.975610\tAcc: 0.843750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [01:00,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 200/288 (69%)\tLoss: 1.034346\tAcc: 0.812500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:18,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 250/288 (87%)\tLoss: 0.829164\tAcc: 0.875000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "288it [01:30,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch Acc: 0.834656\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:17,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 0.0295, Accuracy: 842.0/1023 (82%)\n",
      "\n",
      "Trial left : 3\n",
      "Epoch:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 0/288 (0%)\tLoss: 0.802707\tAcc: 0.937500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:15,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 50/288 (17%)\tLoss: 0.829393\tAcc: 0.812500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:31,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 100/288 (35%)\tLoss: 1.208802\tAcc: 0.718750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:47,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 150/288 (52%)\tLoss: 1.024642\tAcc: 0.812500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [01:02,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 200/288 (69%)\tLoss: 0.783935\tAcc: 0.937500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:18,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 250/288 (87%)\tLoss: 1.068012\tAcc: 0.812500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "288it [01:29,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch Acc: 0.842265\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:15,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 0.0259, Accuracy: 846.0/1023 (83%)\n",
      "\n",
      "Epoch:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 0/288 (0%)\tLoss: 0.878342\tAcc: 0.906250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:14,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 50/288 (17%)\tLoss: 0.619036\tAcc: 0.843750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:29,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 100/288 (35%)\tLoss: 0.482031\tAcc: 0.906250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:44,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 150/288 (52%)\tLoss: 0.954733\tAcc: 0.812500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:59,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 200/288 (69%)\tLoss: 0.923392\tAcc: 0.843750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:14,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 250/288 (87%)\tLoss: 0.843607\tAcc: 0.781250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "288it [01:25,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch Acc: 0.850853\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:16,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 0.0244, Accuracy: 842.0/1023 (82%)\n",
      "\n",
      "Trial left : 3\n",
      "Epoch:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 0/288 (0%)\tLoss: 0.777255\tAcc: 0.750000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:15,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 50/288 (17%)\tLoss: 0.638843\tAcc: 0.937500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:29,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 100/288 (35%)\tLoss: 1.013759\tAcc: 0.843750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:45,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 150/288 (52%)\tLoss: 0.778521\tAcc: 0.843750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [01:02,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 200/288 (69%)\tLoss: 0.496273\tAcc: 0.906250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:17,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 250/288 (87%)\tLoss: 0.879535\tAcc: 0.843750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "288it [01:28,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch Acc: 0.857702\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:16,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 0.0228, Accuracy: 845.0/1023 (83%)\n",
      "\n",
      "Trial left : 2\n",
      "Epoch:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 0/288 (0%)\tLoss: 0.850727\tAcc: 0.812500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:14,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 50/288 (17%)\tLoss: 0.808239\tAcc: 0.812500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:30,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 100/288 (35%)\tLoss: 0.666387\tAcc: 0.906250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:45,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 150/288 (52%)\tLoss: 0.584305\tAcc: 0.906250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [01:00,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 200/288 (69%)\tLoss: 0.518936\tAcc: 0.906250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:18,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 250/288 (87%)\tLoss: 0.481750\tAcc: 0.875000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "288it [01:31,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch Acc: 0.866399\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:15,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 0.0220, Accuracy: 858.0/1023 (84%)\n",
      "\n",
      "Epoch:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 0/288 (0%)\tLoss: 0.666481\tAcc: 0.843750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:14,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 50/288 (17%)\tLoss: 0.814521\tAcc: 0.812500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:30,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 100/288 (35%)\tLoss: 0.594635\tAcc: 0.875000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:45,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 150/288 (52%)\tLoss: 0.428024\tAcc: 0.937500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [01:00,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 200/288 (69%)\tLoss: 0.513066\tAcc: 0.906250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:14,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch: 250/288 (87%)\tLoss: 0.677388\tAcc: 0.843750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "288it [01:26,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch Acc: 0.872921\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:15,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 0.0217, Accuracy: 861.0/1023 (84%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if use_cuda:\n",
    "    net.cuda() # 将网络搬到 GPU 上\n",
    "\n",
    "state = {}\n",
    "state['val_acc'] = []\n",
    "state['best_val_acc'] = 0\n",
    "state['lives'] = 4\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"Epoch: \", epoch+1)\n",
    "    train_acc = train_epoch(net, train_loader, criterion, optimizer, use_cuda)\n",
    "    print(\"Evaluating...\")\n",
    "    val_acc = val_epoch(net, val_loader, criterion, use_cuda)\n",
    "\n",
    "    state['val_acc'].append(val_acc)\n",
    "    if val_acc > state['best_val_acc']:\n",
    "        state['lives'] = 4\n",
    "        state['best_val_acc'] = val_acc\n",
    "    else:\n",
    "        state['lives'] -= 1\n",
    "        print(\"Trial left :\", state['lives'])\n",
    "        if state['lives'] == 2:\n",
    "            optimizer.param_groups[0]['lr'] /= 2\n",
    "        if state['lives'] == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，最后网络在训练集上的精度是 0.872921,在验证集上的精度是 0.84。\n",
    "\n",
    "有了这个网络以后，我们就可以将测试集的数据送到我们的网络，跑出测试集的结果然后去 Kaggle 上提交结果。\n",
    "\n",
    "先看一下我们提交结果的形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10357, 121)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>affenpinscher</th>\n",
       "      <th>afghan_hound</th>\n",
       "      <th>african_hunting_dog</th>\n",
       "      <th>airedale</th>\n",
       "      <th>american_staffordshire_terrier</th>\n",
       "      <th>appenzeller</th>\n",
       "      <th>australian_terrier</th>\n",
       "      <th>basenji</th>\n",
       "      <th>basset</th>\n",
       "      <th>...</th>\n",
       "      <th>toy_poodle</th>\n",
       "      <th>toy_terrier</th>\n",
       "      <th>vizsla</th>\n",
       "      <th>walker_hound</th>\n",
       "      <th>weimaraner</th>\n",
       "      <th>welsh_springer_spaniel</th>\n",
       "      <th>west_highland_white_terrier</th>\n",
       "      <th>whippet</th>\n",
       "      <th>wire-haired_fox_terrier</th>\n",
       "      <th>yorkshire_terrier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000621fb3cbb32d8935728e48679680e</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00102ee9d8eb90812350685311fe5890</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012a730dfa437f5f3613fb75efcd4ce</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001510bc8570bbeee98c8d80c8a95ec1</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001a5f3114548acdefa3d4da05474c2e</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  affenpinscher  afghan_hound  \\\n",
       "0  000621fb3cbb32d8935728e48679680e       0.008333      0.008333   \n",
       "1  00102ee9d8eb90812350685311fe5890       0.008333      0.008333   \n",
       "2  0012a730dfa437f5f3613fb75efcd4ce       0.008333      0.008333   \n",
       "3  001510bc8570bbeee98c8d80c8a95ec1       0.008333      0.008333   \n",
       "4  001a5f3114548acdefa3d4da05474c2e       0.008333      0.008333   \n",
       "\n",
       "   african_hunting_dog  airedale  american_staffordshire_terrier  appenzeller  \\\n",
       "0             0.008333  0.008333                        0.008333     0.008333   \n",
       "1             0.008333  0.008333                        0.008333     0.008333   \n",
       "2             0.008333  0.008333                        0.008333     0.008333   \n",
       "3             0.008333  0.008333                        0.008333     0.008333   \n",
       "4             0.008333  0.008333                        0.008333     0.008333   \n",
       "\n",
       "   australian_terrier   basenji    basset  ...  toy_poodle  toy_terrier  \\\n",
       "0            0.008333  0.008333  0.008333  ...    0.008333     0.008333   \n",
       "1            0.008333  0.008333  0.008333  ...    0.008333     0.008333   \n",
       "2            0.008333  0.008333  0.008333  ...    0.008333     0.008333   \n",
       "3            0.008333  0.008333  0.008333  ...    0.008333     0.008333   \n",
       "4            0.008333  0.008333  0.008333  ...    0.008333     0.008333   \n",
       "\n",
       "     vizsla  walker_hound  weimaraner  welsh_springer_spaniel  \\\n",
       "0  0.008333      0.008333    0.008333                0.008333   \n",
       "1  0.008333      0.008333    0.008333                0.008333   \n",
       "2  0.008333      0.008333    0.008333                0.008333   \n",
       "3  0.008333      0.008333    0.008333                0.008333   \n",
       "4  0.008333      0.008333    0.008333                0.008333   \n",
       "\n",
       "   west_highland_white_terrier   whippet  wire-haired_fox_terrier  \\\n",
       "0                     0.008333  0.008333                 0.008333   \n",
       "1                     0.008333  0.008333                 0.008333   \n",
       "2                     0.008333  0.008333                 0.008333   \n",
       "3                     0.008333  0.008333                 0.008333   \n",
       "4                     0.008333  0.008333                 0.008333   \n",
       "\n",
       "   yorkshire_terrier  \n",
       "0           0.008333  \n",
       "1           0.008333  \n",
       "2           0.008333  \n",
       "3           0.008333  \n",
       "4           0.008333  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_result = pd.read_csv(os.path.join(data_dir, 'sample_submission.csv'))\n",
    "print(sample_result.shape)\n",
    "sample_result.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这次比赛使用的是`logloss`来评估我们模型的结果，我们需要提交测试集中每一张图片对于所有类别的预测结果。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10357\n"
     ]
    }
   ],
   "source": [
    "# test 的数据集定义\n",
    "\n",
    "test_dataset = DogDataset(sample_result.id, labels=[0 for i in range(len(sample_result.id))], root_dir = test_dir, transform=val_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P51\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 323\n",
      "2 / 323\n",
      "3 / 323\n",
      "4 / 323\n",
      "5 / 323\n",
      "6 / 323\n",
      "7 / 323\n",
      "8 / 323\n",
      "9 / 323\n",
      "10 / 323\n",
      "11 / 323\n",
      "12 / 323\n",
      "13 / 323\n",
      "14 / 323\n",
      "15 / 323\n",
      "16 / 323\n",
      "17 / 323\n",
      "18 / 323\n",
      "19 / 323\n",
      "20 / 323\n",
      "21 / 323\n",
      "22 / 323\n",
      "23 / 323\n",
      "24 / 323\n",
      "25 / 323\n",
      "26 / 323\n",
      "27 / 323\n",
      "28 / 323\n",
      "29 / 323\n",
      "30 / 323\n",
      "31 / 323\n",
      "32 / 323\n",
      "33 / 323\n",
      "34 / 323\n",
      "35 / 323\n",
      "36 / 323\n",
      "37 / 323\n",
      "38 / 323\n",
      "39 / 323\n",
      "40 / 323\n",
      "41 / 323\n",
      "42 / 323\n",
      "43 / 323\n",
      "44 / 323\n",
      "45 / 323\n",
      "46 / 323\n",
      "47 / 323\n",
      "48 / 323\n",
      "49 / 323\n",
      "50 / 323\n",
      "51 / 323\n",
      "52 / 323\n",
      "53 / 323\n",
      "54 / 323\n",
      "55 / 323\n",
      "56 / 323\n",
      "57 / 323\n",
      "58 / 323\n",
      "59 / 323\n",
      "60 / 323\n",
      "61 / 323\n",
      "62 / 323\n",
      "63 / 323\n",
      "64 / 323\n",
      "65 / 323\n",
      "66 / 323\n",
      "67 / 323\n",
      "68 / 323\n",
      "69 / 323\n",
      "70 / 323\n",
      "71 / 323\n",
      "72 / 323\n",
      "73 / 323\n",
      "74 / 323\n",
      "75 / 323\n",
      "76 / 323\n",
      "77 / 323\n",
      "78 / 323\n",
      "79 / 323\n",
      "80 / 323\n",
      "81 / 323\n",
      "82 / 323\n",
      "83 / 323\n",
      "84 / 323\n",
      "85 / 323\n",
      "86 / 323\n",
      "87 / 323\n",
      "88 / 323\n",
      "89 / 323\n",
      "90 / 323\n",
      "91 / 323\n",
      "92 / 323\n",
      "93 / 323\n",
      "94 / 323\n",
      "95 / 323\n",
      "96 / 323\n",
      "97 / 323\n",
      "98 / 323\n",
      "99 / 323\n",
      "100 / 323\n",
      "101 / 323\n",
      "102 / 323\n",
      "103 / 323\n",
      "104 / 323\n",
      "105 / 323\n",
      "106 / 323\n",
      "107 / 323\n",
      "108 / 323\n",
      "109 / 323\n",
      "110 / 323\n",
      "111 / 323\n",
      "112 / 323\n",
      "113 / 323\n",
      "114 / 323\n",
      "115 / 323\n",
      "116 / 323\n",
      "117 / 323\n",
      "118 / 323\n",
      "119 / 323\n",
      "120 / 323\n",
      "121 / 323\n",
      "122 / 323\n",
      "123 / 323\n",
      "124 / 323\n",
      "125 / 323\n",
      "126 / 323\n",
      "127 / 323\n",
      "128 / 323\n",
      "129 / 323\n",
      "130 / 323\n",
      "131 / 323\n",
      "132 / 323\n",
      "133 / 323\n",
      "134 / 323\n",
      "135 / 323\n",
      "136 / 323\n",
      "137 / 323\n",
      "138 / 323\n",
      "139 / 323\n",
      "140 / 323\n",
      "141 / 323\n",
      "142 / 323\n",
      "143 / 323\n",
      "144 / 323\n",
      "145 / 323\n",
      "146 / 323\n",
      "147 / 323\n",
      "148 / 323\n",
      "149 / 323\n",
      "150 / 323\n",
      "151 / 323\n",
      "152 / 323\n",
      "153 / 323\n",
      "154 / 323\n",
      "155 / 323\n",
      "156 / 323\n",
      "157 / 323\n",
      "158 / 323\n",
      "159 / 323\n",
      "160 / 323\n",
      "161 / 323\n",
      "162 / 323\n",
      "163 / 323\n",
      "164 / 323\n",
      "165 / 323\n",
      "166 / 323\n",
      "167 / 323\n",
      "168 / 323\n",
      "169 / 323\n",
      "170 / 323\n",
      "171 / 323\n",
      "172 / 323\n",
      "173 / 323\n",
      "174 / 323\n",
      "175 / 323\n",
      "176 / 323\n",
      "177 / 323\n",
      "178 / 323\n",
      "179 / 323\n",
      "180 / 323\n",
      "181 / 323\n",
      "182 / 323\n",
      "183 / 323\n",
      "184 / 323\n",
      "185 / 323\n",
      "186 / 323\n",
      "187 / 323\n",
      "188 / 323\n",
      "189 / 323\n",
      "190 / 323\n",
      "191 / 323\n",
      "192 / 323\n",
      "193 / 323\n",
      "194 / 323\n",
      "195 / 323\n",
      "196 / 323\n",
      "197 / 323\n",
      "198 / 323\n",
      "199 / 323\n",
      "200 / 323\n",
      "201 / 323\n",
      "202 / 323\n",
      "203 / 323\n",
      "204 / 323\n",
      "205 / 323\n",
      "206 / 323\n",
      "207 / 323\n",
      "208 / 323\n",
      "209 / 323\n",
      "210 / 323\n",
      "211 / 323\n",
      "212 / 323\n",
      "213 / 323\n",
      "214 / 323\n",
      "215 / 323\n",
      "216 / 323\n",
      "217 / 323\n",
      "218 / 323\n",
      "219 / 323\n",
      "220 / 323\n",
      "221 / 323\n",
      "222 / 323\n",
      "223 / 323\n",
      "224 / 323\n",
      "225 / 323\n",
      "226 / 323\n",
      "227 / 323\n",
      "228 / 323\n",
      "229 / 323\n",
      "230 / 323\n",
      "231 / 323\n",
      "232 / 323\n",
      "233 / 323\n",
      "234 / 323\n",
      "235 / 323\n",
      "236 / 323\n",
      "237 / 323\n",
      "238 / 323\n",
      "239 / 323\n",
      "240 / 323\n",
      "241 / 323\n",
      "242 / 323\n",
      "243 / 323\n",
      "244 / 323\n",
      "245 / 323\n",
      "246 / 323\n",
      "247 / 323\n",
      "248 / 323\n",
      "249 / 323\n",
      "250 / 323\n",
      "251 / 323\n",
      "252 / 323\n",
      "253 / 323\n",
      "254 / 323\n",
      "255 / 323\n",
      "256 / 323\n",
      "257 / 323\n",
      "258 / 323\n",
      "259 / 323\n",
      "260 / 323\n",
      "261 / 323\n",
      "262 / 323\n",
      "263 / 323\n",
      "264 / 323\n",
      "265 / 323\n",
      "266 / 323\n",
      "267 / 323\n",
      "268 / 323\n",
      "269 / 323\n",
      "270 / 323\n",
      "271 / 323\n",
      "272 / 323\n",
      "273 / 323\n",
      "274 / 323\n",
      "275 / 323\n",
      "276 / 323\n",
      "277 / 323\n",
      "278 / 323\n",
      "279 / 323\n",
      "280 / 323\n",
      "281 / 323\n",
      "282 / 323\n",
      "283 / 323\n",
      "284 / 323\n",
      "285 / 323\n",
      "286 / 323\n",
      "287 / 323\n",
      "288 / 323\n",
      "289 / 323\n",
      "290 / 323\n",
      "291 / 323\n",
      "292 / 323\n",
      "293 / 323\n",
      "294 / 323\n",
      "295 / 323\n",
      "296 / 323\n",
      "297 / 323\n",
      "298 / 323\n",
      "299 / 323\n",
      "300 / 323\n",
      "301 / 323\n",
      "302 / 323\n",
      "303 / 323\n",
      "304 / 323\n",
      "305 / 323\n",
      "306 / 323\n",
      "307 / 323\n",
      "308 / 323\n",
      "309 / 323\n",
      "310 / 323\n",
      "311 / 323\n",
      "312 / 323\n",
      "313 / 323\n",
      "314 / 323\n",
      "315 / 323\n",
      "316 / 323\n",
      "317 / 323\n",
      "318 / 323\n",
      "319 / 323\n",
      "320 / 323\n",
      "321 / 323\n",
      "322 / 323\n",
      "323 / 323\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "\n",
    "# 定义Softmax，将输出缩放为概率的形式\n",
    "softmax = torch.nn.Softmax()\n",
    "\n",
    "first = True\n",
    "total_batch = int(len(test_dataset) / batch_size)\n",
    "for batch_idx, (x, y) in enumerate(test_loader):\n",
    "    print(\"{} / {}\".format(batch_idx, total_batch))\n",
    "    if use_cuda:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "    x = Variable(x)\n",
    "    y = Variable(y)\n",
    "    prediction = softmax(net(x)).detach().cpu().numpy()\n",
    "    if first:\n",
    "        results = prediction\n",
    "        first = False\n",
    "    else:\n",
    "        results = np.concatenate((results, prediction), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10357, 120)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>affenpinscher</th>\n",
       "      <th>afghan_hound</th>\n",
       "      <th>african_hunting_dog</th>\n",
       "      <th>airedale</th>\n",
       "      <th>american_staffordshire_terrier</th>\n",
       "      <th>appenzeller</th>\n",
       "      <th>australian_terrier</th>\n",
       "      <th>basenji</th>\n",
       "      <th>basset</th>\n",
       "      <th>beagle</th>\n",
       "      <th>...</th>\n",
       "      <th>toy_poodle</th>\n",
       "      <th>toy_terrier</th>\n",
       "      <th>vizsla</th>\n",
       "      <th>walker_hound</th>\n",
       "      <th>weimaraner</th>\n",
       "      <th>welsh_springer_spaniel</th>\n",
       "      <th>west_highland_white_terrier</th>\n",
       "      <th>whippet</th>\n",
       "      <th>wire-haired_fox_terrier</th>\n",
       "      <th>yorkshire_terrier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000621fb3cbb32d8935728e48679680e</th>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.003434</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>3.316232e-05</td>\n",
       "      <td>9.783248e-05</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00102ee9d8eb90812350685311fe5890</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>2.432131e-05</td>\n",
       "      <td>4.889337e-05</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0012a730dfa437f5f3613fb75efcd4ce</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.003933</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>8.445907e-07</td>\n",
       "      <td>8.160892e-07</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.004516</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001510bc8570bbeee98c8d80c8a95ec1</th>\n",
       "      <td>0.070168</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.003060</td>\n",
       "      <td>0.006820</td>\n",
       "      <td>0.004348</td>\n",
       "      <td>7.603069e-04</td>\n",
       "      <td>2.698609e-03</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006677</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>0.002578</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.010422</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>0.005235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001a5f3114548acdefa3d4da05474c2e</th>\n",
       "      <td>0.007039</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>1.850218e-03</td>\n",
       "      <td>1.909158e-04</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>0.001196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  affenpinscher  afghan_hound  \\\n",
       "id                                                              \n",
       "000621fb3cbb32d8935728e48679680e       0.000036      0.003434   \n",
       "00102ee9d8eb90812350685311fe5890       0.000005      0.000006   \n",
       "0012a730dfa437f5f3613fb75efcd4ce       0.000001      0.003933   \n",
       "001510bc8570bbeee98c8d80c8a95ec1       0.070168      0.003006   \n",
       "001a5f3114548acdefa3d4da05474c2e       0.007039      0.003949   \n",
       "\n",
       "                                  african_hunting_dog  airedale  \\\n",
       "id                                                                \n",
       "000621fb3cbb32d8935728e48679680e             0.000008  0.000010   \n",
       "00102ee9d8eb90812350685311fe5890             0.000001  0.000001   \n",
       "0012a730dfa437f5f3613fb75efcd4ce             0.000005  0.000023   \n",
       "001510bc8570bbeee98c8d80c8a95ec1             0.000581  0.003060   \n",
       "001a5f3114548acdefa3d4da05474c2e             0.000487  0.000429   \n",
       "\n",
       "                                  american_staffordshire_terrier  appenzeller  \\\n",
       "id                                                                              \n",
       "000621fb3cbb32d8935728e48679680e                        0.000012     0.000033   \n",
       "00102ee9d8eb90812350685311fe5890                        0.000025     0.000040   \n",
       "0012a730dfa437f5f3613fb75efcd4ce                        0.000004     0.000011   \n",
       "001510bc8570bbeee98c8d80c8a95ec1                        0.006820     0.004348   \n",
       "001a5f3114548acdefa3d4da05474c2e                        0.000265     0.000268   \n",
       "\n",
       "                                  australian_terrier       basenji    basset  \\\n",
       "id                                                                             \n",
       "000621fb3cbb32d8935728e48679680e        3.316232e-05  9.783248e-05  0.000095   \n",
       "00102ee9d8eb90812350685311fe5890        2.432131e-05  4.889337e-05  0.000010   \n",
       "0012a730dfa437f5f3613fb75efcd4ce        8.445907e-07  8.160892e-07  0.000100   \n",
       "001510bc8570bbeee98c8d80c8a95ec1        7.603069e-04  2.698609e-03  0.002990   \n",
       "001a5f3114548acdefa3d4da05474c2e        1.850218e-03  1.909158e-04  0.001098   \n",
       "\n",
       "                                    beagle  ...  toy_poodle  toy_terrier  \\\n",
       "id                                          ...                            \n",
       "000621fb3cbb32d8935728e48679680e  0.000301  ...    0.000103     0.000056   \n",
       "00102ee9d8eb90812350685311fe5890  0.000003  ...    0.000067     0.000021   \n",
       "0012a730dfa437f5f3613fb75efcd4ce  0.000014  ...    0.000003     0.000008   \n",
       "001510bc8570bbeee98c8d80c8a95ec1  0.001681  ...    0.006677     0.000997   \n",
       "001a5f3114548acdefa3d4da05474c2e  0.000247  ...    0.003087     0.000204   \n",
       "\n",
       "                                    vizsla  walker_hound  weimaraner  \\\n",
       "id                                                                     \n",
       "000621fb3cbb32d8935728e48679680e  0.000019      0.000076    0.000021   \n",
       "00102ee9d8eb90812350685311fe5890  0.000003      0.000009    0.000003   \n",
       "0012a730dfa437f5f3613fb75efcd4ce  0.000006      0.000248    0.000053   \n",
       "001510bc8570bbeee98c8d80c8a95ec1  0.000992      0.001750    0.001878   \n",
       "001a5f3114548acdefa3d4da05474c2e  0.000113      0.000676    0.000137   \n",
       "\n",
       "                                  welsh_springer_spaniel  \\\n",
       "id                                                         \n",
       "000621fb3cbb32d8935728e48679680e                0.000241   \n",
       "00102ee9d8eb90812350685311fe5890                0.000008   \n",
       "0012a730dfa437f5f3613fb75efcd4ce                0.004516   \n",
       "001510bc8570bbeee98c8d80c8a95ec1                0.002578   \n",
       "001a5f3114548acdefa3d4da05474c2e                0.000888   \n",
       "\n",
       "                                  west_highland_white_terrier   whippet  \\\n",
       "id                                                                        \n",
       "000621fb3cbb32d8935728e48679680e                     0.000033  0.000100   \n",
       "00102ee9d8eb90812350685311fe5890                     0.000533  0.000003   \n",
       "0012a730dfa437f5f3613fb75efcd4ce                     0.000013  0.000359   \n",
       "001510bc8570bbeee98c8d80c8a95ec1                     0.000809  0.010422   \n",
       "001a5f3114548acdefa3d4da05474c2e                     0.005376  0.000265   \n",
       "\n",
       "                                  wire-haired_fox_terrier  yorkshire_terrier  \n",
       "id                                                                            \n",
       "000621fb3cbb32d8935728e48679680e                 0.000066           0.000158  \n",
       "00102ee9d8eb90812350685311fe5890                 0.000015           0.000004  \n",
       "0012a730dfa437f5f3613fb75efcd4ce                 0.000035           0.000011  \n",
       "001510bc8570bbeee98c8d80c8a95ec1                 0.000844           0.005235  \n",
       "001a5f3114548acdefa3d4da05474c2e                 0.003620           0.001196  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=results, index=sample_result.id, columns=le.classes_)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"submit.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到结果以后可以去 Kaggle 网站提交结果：https://www.kaggle.com/c/dog-breed-identification/submissions\n",
    "\n",
    "应该会拿到排名在60%的成绩，由于这次做的比较基础，并且也没有用到多个模型的融合，所以效果还有很大的进步空间。\n",
    "\n",
    "感谢您的阅读，加油！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
